model_list:
  - model_name: GLM-4.6-nano
    litellm_params:
      api_type: openai
      model: z-ai/glm-4.6:thinking
      api_base: https://nano-gpt.com/api/v1thinking
      api_key: ${NANOGPT_API_KEY}
      supports_reasoning: True
      request_timeout: 540

  - model_name: GLM-4.7
    litellm_params:
      api_type: openai
      model: GLM-4.7
      api_base: https://api.z.ai/api/coding/paas/v4
      api_key: ${GLM_API_KEY}
      supports_reasoning: True
      request_timeout: 540
    parameters:
      temperature:
        default: 1.0
        allow_override: false  # Always force t=1.0 for this model
      top_p:
        default: 0.95
        allow_override: false
      top_k:
        default: 40
        allow_override: false

  - model_name: MiniMax-M2
    litellm_params:
      api_type: openai
      model: MiniMax-M2
      api_base: https://api.minimax.io/v1
      api_key: ${MINIMAX_API_KEY}
      request_timeout: 540

  - model_name: MiniMax-M2.1
    litellm_params:
      api_type: openai
      model: MiniMax-M2.1
      api_base: https://api.minimax.io/v1
      api_key: ${MINIMAX_API_KEY}
      request_timeout: 540
    
  - model_name: MiniMax-M2-nano
    litellm_params:
      api_type: openai
      model: MiniMax-M2
      api_base: https://nano-gpt.com/api/v1thinking
      api_key: ${NANOGPT_API_KEY}
      supports_reasoning: True
      request_timeout: 540

  - model_name: MiniMax-M2-synthetic
    litellm_params:
      api_type: openai
      model: hf:MiniMaxAI/MiniMax-M2
      api_base: https://api.synthetic.new/openai/v1
      api_key: ${SYNTHETIC_API_KEY}
      supports_reasoning: True
      request_timeout: 540

  - model_name: Kimi-K2-Thinking-nano
    litellm_params:
      api_type: openai
      model: moonshotai/kimi-k2-thinking
      api_base: https://nano-gpt.com/api/v1thinking
      api_key: ${NANOGPT_API_KEY}
      supports_reasoning: True
      request_timeout: 540

  - model_name: Kimi-K2-Thinking-synthetic
    litellm_params:
      api_type: openai
      model: hf:moonshotai/Kimi-K2-Thinking
      api_base: https://api.synthetic.new/openai/v1
      api_key: ${SYNTHETIC_API_KEY}
      supports_reasoning: True
      request_timeout: 540

# Router / reliability settings
router_settings:
  # Try the active model up to 2 times
  num_retries: 1

proxy_settings:
  server:
    host: 127.0.0.1
    port: 7979
  # Enable/disable experimental OpenAI Responses API support
  enable_responses_endpoint: false

forwarder_settings:
  listen:
    host: 0.0.0.0
    port: 6969
  target:
    host: 127.0.0.1
    port: 7979
