model_list:
- model_name: GLM-4.6-nano
  protected: true
  model_params:
    api_type: openai
    model: z-ai/glm-4.6:thinking
    api_base: https://nano-gpt.com/api/v1thinking
    api_key: ${NANOGPT_API_KEY}
    supports_reasoning: true
    request_timeout: 540
- model_name: GLM-4.7
  protected: true
  model_params:
    api_type: openai
    model: GLM-4.7
    api_base: https://api.z.ai/api/coding/paas/v4
    api_key: ${GLM_API_KEY}
    thinking:
      type: enabled
    request_timeout: 540
    parameters:
      temperature:
        default: 0.9
        allow_override: false
      top_p:
        default: 0.95
        allow_override: false
  modules:
    upstream:
      enabled: true
      response:
      - swap_reasoning_content
      swap_reasoning_content:
        mode: reasoning_to_content
        think_tag: think
        think_open:
          prefix: ''
          suffix: ''
        think_close:
          prefix: ''
          suffix: ''
        include_newline: false
- model_name: MiniMax-M2.1
  protected: true
  model_params:
    api_type: openai
    model: MiniMax-M2.1
    api_base: https://api.minimax.io/v1
    api_key: ${MINIMAX_API_KEY}
    request_timeout: 540
    parameters:
      temperature:
        default: 1.0
        allow_override: false
      top_p:
        default: 0.95
        allow_override: false
      top_k:
        default: 40
        allow_override: false
- model_name: MiniMax-M2.1:oc
  protected: true
  model_params:
    api_type: anthropic
    model: MiniMax-M2.1
    api_base: https://api.minimax.io/anthropic/v1
    api_key: ${MINIMAX_API_KEY}
    anthropic_version: '2023-06-01'
    request_timeout: 540
    parameters:
      temperature:
        default: 1.0
        allow_override: false
      top_p:
        default: 0.95
        allow_override: false
      top_k:
        default: 40
        allow_override: false
- model_name: GLM-4.7:oc
  model_params:
    api_base: https://api.z.ai/api/anthropic/v1
    model: GLM-4.7
    request_timeout: 540
    api_type: anthropic
    supports_reasoning: true
    parameters:
      temperature:
        default: 1
        allow_override: false
      top_p:
        default: 0.95
        allow_override: false
      top_k:
        default: 40
        allow_override: false
      effort:
        default: high
        allow_override: false
    api_key: ${GLM_API_KEY}
  protected: true
- model_name: MiniMax-M2-nano
  protected: true
  model_params:
    api_type: openai
    model: MiniMax-M2
    api_base: https://nano-gpt.com/api/v1thinking
    api_key: ${NANOGPT_API_KEY}
    supports_reasoning: true
    request_timeout: 540
- model_name: Kimi-K2-Thinking-nano
  model_params:
    api_base: https://nano-gpt.com/api/v1thinking
    model: moonshotai/kimi-k2-thinking
    request_timeout: 540
    api_type: openai
    supports_reasoning: true
    api_key: ${NANOGPT_API_KEY}
  modules:
    upstream:
      enabled: true
      response:
      - parse_tags
      parse_tags:
        template_path: configs/jinja_templates/k2thinking.jinja
        parse_thinking: false
        parse_tool_calls: true
  protected: true
- model_name: glm_local
  model_params:
    api_base: http://nid-sc-28:16667/v1
    model: GLM_air_fp8
    request_timeout: 180
    api_type: openai
    supports_reasoning: true
  protected: false
- model_name: glm_local_AWQ
  model_params:
    api_base: http://nid-sc-28:16161/v1
    model: GLM_air_awq
    request_timeout: 30
    api_type: openai
    supports_reasoning: true
    parameters:
      tool_choice:
        default: none
        allow_override: false
  modules:
    upstream:
      enabled: true
      response:
      - parse_tags
      parse_tags:
        template_path: configs/jinja_templates/glm_4.5_air.jinja
        think_tag: think
        tool_arg_format: xml
        tool_tag: tool_call
        parse_thinking: true
        parse_tool_calls: true
  protected: false
- model_name: giga-2-pro
  model_params:
    api_base: http://nid-sc-29:9996/v1
    model: GigaChat-2-Pro
    request_timeout: 60
    api_type: openai
    supports_reasoning: false
    parameters:
      temperature:
        default: 0.85
        allow_override: true
  protected: false
- model_name: giga-3-ultra
  model_params:
    api_base: http://nid-sc-29:9996/v1
    model: GigaChat-3-Ultra
    request_timeout: 60
    api_type: openai
    supports_reasoning: false
    parameters:
      temperature:
        default: 0.85
        allow_override: true
  protected: false
router_settings:
  num_retries: 1
proxy_settings:
  debug: false  # Enable debug logging -> logs/console.log
  server:
    host: 0.0.0.0
    port: 7979
  enable_responses_endpoint: false
  enable_messages_endpoint: true
  logging:
    log_parsed_response: true
    log_parsed_stream: true
  modules:
    upstream:
      enabled: false
      response:
      - parse_tags
      - swap_reasoning_content
      paths:
      - /chat/completions
      parse_tags:
        parse_thinking: true
        parse_tool_calls: true
        think_tag: think
        tool_arg_format: xml
        tool_tag: tool_call
      swap_reasoning_content:
        mode: reasoning_to_content
        think_tag: think
        think_open:
          prefix: ''
          suffix: ''
        think_close:
          prefix: ''
          suffix: ''
        include_newline: true
    downstream:
      enabled: false
      request: []
forwarder_settings:
  debug: false  # Enable debug logging -> logs/console_forwarder.log
  listen:
    host: 0.0.0.0
    port: 6969
  target:
    host: 127.0.0.1
    port: 7979
http_forwarder_settings:
  debug: false  # Enable debug logging -> logs/console_http_forwarder.log
  preserve_host: true
  listen:
    host: 0.0.0.0
    port: 6969
  target:
    scheme: http
    host: 127.0.0.1
    port: 7979
database:
  backend: sqlite
  connection:
    sqlite:
      path: logs/yaLLM.db
  pool_size: 5
  max_overflow: 10
